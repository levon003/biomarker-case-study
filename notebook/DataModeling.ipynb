{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e04e4b61-0008-4438-b3d5-90608b5b16d9",
   "metadata": {},
   "source": [
    "Data Modeling\n",
    "===\n",
    "\n",
    "Prediction the targets based on patient and biomarker data.\n",
    "\n",
    "### Model\n",
    "\n",
    "What model should we use for this modeling problem?\n",
    "We have an ambiguous classification problem with unclear intended use-cases.\n",
    "Further, the data contains a large number of possible raw features, contains some missing data, and is structured.\n",
    "This is an excellent fit for gradient boosting machines (GBMs).\n",
    "The most prominent GBM implementations are LightGBM and XGBoost, but we'll just use the newer scikit-learn implementation (which is based on and benchmarks competitively with LightGBM).\n",
    "\n",
    "#### Other options\n",
    "Future work could explore other model classes, particularly if a particular use-case was identified for which a different model would be a better fit.\n",
    "\n",
    "A few options worth considering:\n",
    "\n",
    " - Models like logistic regression have the benefit of familiarity to clinical audiences. Alternately, presenting the correlations or odds ratios for just a few of the patient variables could be useful for some audiences (at the cost of predictive power).\n",
    " - Alternative models could include other highly intepretable models. For example, an integer-only risk-scoring model (e.g. fit using [FasterRisk](https://github.com/jiachangliu/FasterRisk)) could be worth exploring.\n",
    " - Deep learning models could be used to learn separate embeddings for patients and biomarkers. These embeddings could be useful for more than just the given classification problem.\n",
    "\n",
    "### Data and modeling features\n",
    "\n",
    "Most of the feature visualization and development work is in the `DataExploration` notebook (in this same directory).\n",
    "\n",
    "#### Other options\n",
    "\n",
    "### Evaluation and metrics\n",
    "\n",
    "A downside to this approach is that folds have non-consistent sizes, making comparison between models challenging.\n",
    "In other words, the training set will be larger when predicting on patients at the smallest institutions.\n",
    "\n",
    "#### Other options\n",
    "\n",
    "### Model optimization and hyperparameter tuning\n",
    "\n",
    "I trained all models on a single CPU core of a Macbook Air.\n",
    "Therefore, I both didn't parellelize hyperparameter tuning (due to low available memory) and didn't train very many models during hyperparameter tuning.\n",
    "As a result, I was selective about the experiments that I ran and the parameters I varied together.\n",
    "Following [Google's tuning guidance](https://github.com/google-research/tuning_playbook#a-scientific-approach-to-improving-model-performance), I used iterative tuning within hand-designed parameter search spaces. \n",
    "That's an unneccessarily fancy way of \n",
    "\n",
    "Here are some things I would have liked to do but didn't get around to doing:\n",
    " - My validation approach (20-fold cross validation) is overly simplistic; realistically there is leakage between train and test, as patient hospitalizations are not independent events. A minimally reasonable approach, and the reason the `hdf` below contains provider information, would be to create 1 test fold for each provider. Creating a single temporally-bounded test set could be reasonable as well, although it would have to be done carefully.\n",
    " - Given the small number of covariates, \n",
    " - The hyperparameter search I implemented is very cursory. Given the small size of the dataset, doing a more detailed search is probably overkill, but I would still expect to use a more elaborate test harness in situations where prediction is important.\n",
    " - The definition of hospitalizations I used (as implemented in `covid_modeling.io.DataLoader`) is probably questionable; modeling in a situation like this (where I have no knowledge of the data-generating process) is fairly unreasonable.  If there were no mechanism to better understand the data-generating process (such as via a SME or dataset documentation), drawing conclusions from this data would be unethical (and unwarranted).  In particular, noise in the application of SNOMED CT codes is something I mention in the `DataExploration` notebook, but I ultimately decided to be out-of-scope for this particular exploration. (For example, one might try to impute missing reason-codes or correct erroneous reason codes where there is reason to suspect a COVID-19 diagnosis.)\n",
    " - \"Interpretable\" is always contextual. I chose logistic regression because it is a language familiar to many data scientists and subject-matter experts---potentially even more familiar than a decision tree!  However, for particular types of clinical practitioners, I would try to create a much simpler model (e.g. using only a single covariate, or the integer-only model mentioned above).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "418c6d10-ba7b-4833-895a-4a26f82b955c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import bcs.data_loader\n",
    "import bcs.modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad452564-ec6a-41a2-a5f1-c1ead84e0dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = (Path.cwd() / \"..\" / \"data\").resolve()\n",
    "assert data_dir.exists()\n",
    "figures_dir = (Path.cwd() / \"..\" / \"figures\").resolve()\n",
    "figures_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19bd3be5-8cf2-4f65-a2bb-4701dfbd6e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl = bcs.data_loader.DataLoader(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5313f0d-7896-40d1-9980-8a2da3c86f2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf = dl.get_patient_dataframe()\n",
    "bdf = dl.get_biomarker_dataframe()\n",
    "tdf = dl.get_target_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "965bcdbc-e786-4426-9ebf-5fbe5cf242d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1734, 15174)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf = pd.merge(tdf, pdf, how=\"left\", left_on=\"patient_id\", right_index=True)\n",
    "mdf = pd.merge(mdf, bdf, how=\"left\", left_on=\"biomarker_id\", right_index=True)\n",
    "mdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92508de-4926-4937-85d0-bc12567f11af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# config = bcs.modeling.ModelingConfig()\n",
    "# model_evaluator = bcs.modeling.ModelEvaluator(config, mdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "800e1e02-7487-4ff6-9187-bf4843c305d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3f080de-2b20-476e-92dd-38146b5e6bfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelingConfig(experiment_name='test', patient_feature_action='keep', biomarker_feature_action='keep', biomarker_svd_n_components=None, is_disease_sub_type_ordered=True, excluded_columns=['status_alcohol_usage', 'status_exercise_frequency', 'status_bmi_level', 'status_days_since_diagnosis'], cv_column='institution_name', target_column='target_label', gbm_learning_rate=0.1, gbm_max_iter=100, gbm_max_leaf_nodes=31, gbm_min_samples_leaf=20, gbm_l2_regularization=0.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcs.modeling.ModelingConfig(**{\"experiment_name\": \"test\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5944b7b2-2164-42df-abc0-bb53404a484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = []\n",
    "named_models = [\n",
    "    {\n",
    "        \"experiment_name\": \"all\",\n",
    "    },\n",
    "    {\n",
    "        \"experiment_name\": \"patient_only\",\n",
    "        \"biomarker_feature_action\": \"exclude\",\n",
    "    },\n",
    "    {\n",
    "        \"experiment_name\": \"patient_only_unorderedDisease\",\n",
    "        \"biomarker_feature_action\": \"exclude\",\n",
    "        \"is_disease_sub_type_ordered\": False,\n",
    "    },\n",
    "    {\n",
    "        \"experiment_name\": \"biomarker_only\",\n",
    "        \"patient_feature_action\": \"exclude\",\n",
    "    },\n",
    "    {\n",
    "        \"experiment_name\": \"biomarker_only_svd\",\n",
    "        \"patient_feature_action\": \"exclude\",\n",
    "        \"biomarker_feature_action\": \"svd\",\n",
    "    },\n",
    "]\n",
    "for named_model in named_models\n",
    "    config = bcs.modeling.ModelingConfig(\n",
    "        gbm_learning_rate=0.2,\n",
    "        gbm_max_iter=200,\n",
    "        gbm_max_leaf_nodes=31,\n",
    "        gbm_min_samples_leaf=10,\n",
    "        gbm_l2_regularization=0.01,\n",
    "        **named_model,\n",
    "    )\n",
    "    configs.append(config)\n",
    "assert len(configs) == len(set([c.experiment_name for c in configs])), \"Experiment names not unique.\"\n",
    "len(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50eca6-0f5a-4798-95c1-87946b13982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "for config in tqdm(configs):\n",
    "    if config.experiment_name in model_map:\n",
    "        continue\n",
    "    else:\n",
    "        model_evaluator = bcs.modeling.ModelEvaluator(config, mdf)\n",
    "        model = model_evaluator.train_and_evaluate()\n",
    "        model_map[config.experiment_name] = model\n",
    "\n",
    "len(model_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77736e60-bbac-4a2d-afab-5b67e3677885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c552f3-e621-4c5f-9d66-927a1a315afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47e314-670d-4909-9774-ecda039a64db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19eaa824-f306-4f67-81a0-3d39ff948782",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "These experiments take a while to run (as the tqdm output below suggests), so they are maintained here as a record but not intended to be executed in normal cell execution flow. They were used to set the values used in the configurations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89e4fb54-fa68-4d32-85e9-c74e6198eb63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs = []\n",
    "for gbm_learning_rate in [0.1, 0.2]:\n",
    "    for gbm_max_iter in [100, 200]:\n",
    "        for gbm_max_leaf_nodes in [31, 63]:\n",
    "            for gbm_min_samples_leaf in [10, 20]:\n",
    "                for gbm_l2_regularization in [0.0, 0.02]:\n",
    "                    config = bcs.modeling.ModelingConfig(\n",
    "                        experiment_name=f\"gbm_lr{gbm_learning_rate:.1f}_it{gbm_max_iter}_max{gbm_max_leaf_nodes}_min{gbm_min_samples_leaf}_r{gbm_l2_regularization:.2f}\",\n",
    "                        gbm_learning_rate=gbm_learning_rate,\n",
    "                        gbm_max_iter=gbm_max_iter,\n",
    "                        gbm_max_leaf_nodes=gbm_max_leaf_nodes,\n",
    "                        gbm_min_samples_leaf=gbm_min_samples_leaf,\n",
    "                        gbm_l2_regularization=gbm_l2_regularization,\n",
    "                        biomarker_feature_action=\"exclude\",\n",
    "                    )\n",
    "                    configs.append(config)\n",
    "assert len(configs) == len({c.experiment_name for c in configs}), \"Experiment names not unique.\"\n",
    "len(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4dae96f-29c8-4f2f-8e19-fa8ab97aaca2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs = []\n",
    "for gbm_learning_rate in [0.1, 0.2]:\n",
    "    for gbm_max_iter in [100, 200]:\n",
    "        for gbm_max_leaf_nodes in [31, 63]:\n",
    "            for gbm_min_samples_leaf in [10, 20]:\n",
    "                config = bcs.modeling.ModelingConfig(\n",
    "                    experiment_name=f\"gbm_lr{gbm_learning_rate:.1f}_it{gbm_max_iter}_max{gbm_max_leaf_nodes}_min{gbm_min_samples_leaf}\",\n",
    "                    gbm_learning_rate=gbm_learning_rate,\n",
    "                    gbm_max_iter=gbm_max_iter,\n",
    "                    gbm_max_leaf_nodes=gbm_max_leaf_nodes,\n",
    "                    gbm_min_samples_leaf=gbm_min_samples_leaf,\n",
    "                    gbm_l2_regularization=0.01,\n",
    "                    biomarker_feature_action=\"keep\",\n",
    "                )\n",
    "                configs.append(config)\n",
    "assert len(configs) == len({c.experiment_name for c in configs}), \"Experiment names not unique.\"\n",
    "len(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f50636b-c97e-4968-aec9-634a0da45b94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [3:05:01<00:00, 693.84s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_list = []\n",
    "for config in tqdm(configs):\n",
    "    model_evaluator = bcs.modeling.ModelEvaluator(config, mdf)\n",
    "    model_metrics_list = model_evaluator.train_and_evaluate()\n",
    "    metrics_list.extend(model_metrics_list)\n",
    "len(metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0ef2445-275b-413c-af04-8378a29bde11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1_pos</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>gbm_lr0.1_it100_max31_min20_r0.02</td>\n",
       "      <td>0.751442</td>\n",
       "      <td>0.273187</td>\n",
       "      <td>0.606639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gbm_lr0.1_it100_max31_min20_r0.00</td>\n",
       "      <td>0.737601</td>\n",
       "      <td>0.242928</td>\n",
       "      <td>0.605682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>gbm_lr0.1_it100_max63_min20_r0.00</td>\n",
       "      <td>0.742215</td>\n",
       "      <td>0.258706</td>\n",
       "      <td>0.603535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gbm_lr0.1_it100_max31_min10_r0.02</td>\n",
       "      <td>0.751442</td>\n",
       "      <td>0.282862</td>\n",
       "      <td>0.601420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gbm_lr0.1_it100_max31_min10_r0.00</td>\n",
       "      <td>0.747982</td>\n",
       "      <td>0.255537</td>\n",
       "      <td>0.598858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>gbm_lr0.1_it200_max31_min20_r0.00</td>\n",
       "      <td>0.728950</td>\n",
       "      <td>0.246795</td>\n",
       "      <td>0.594175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>gbm_lr0.1_it200_max63_min20_r0.00</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.253918</td>\n",
       "      <td>0.592889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>gbm_lr0.1_it100_max63_min20_r0.02</td>\n",
       "      <td>0.737024</td>\n",
       "      <td>0.242525</td>\n",
       "      <td>0.592759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>gbm_lr0.1_it200_max31_min20_r0.02</td>\n",
       "      <td>0.732987</td>\n",
       "      <td>0.263911</td>\n",
       "      <td>0.590530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>gbm_lr0.1_it200_max31_min10_r0.02</td>\n",
       "      <td>0.738178</td>\n",
       "      <td>0.295031</td>\n",
       "      <td>0.589123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>gbm_lr0.2_it100_max63_min20_r0.02</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.251572</td>\n",
       "      <td>0.585793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>gbm_lr0.2_it100_max63_min20_r0.00</td>\n",
       "      <td>0.714533</td>\n",
       "      <td>0.248862</td>\n",
       "      <td>0.584456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>gbm_lr0.1_it200_max63_min20_r0.02</td>\n",
       "      <td>0.722030</td>\n",
       "      <td>0.260736</td>\n",
       "      <td>0.584347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>gbm_lr0.2_it100_max31_min20_r0.00</td>\n",
       "      <td>0.724337</td>\n",
       "      <td>0.246057</td>\n",
       "      <td>0.583764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>gbm_lr0.2_it100_max31_min10_r0.00</td>\n",
       "      <td>0.727220</td>\n",
       "      <td>0.275651</td>\n",
       "      <td>0.582768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>gbm_lr0.2_it100_max31_min20_r0.02</td>\n",
       "      <td>0.726644</td>\n",
       "      <td>0.254717</td>\n",
       "      <td>0.582320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>gbm_lr0.1_it200_max31_min10_r0.00</td>\n",
       "      <td>0.716263</td>\n",
       "      <td>0.261261</td>\n",
       "      <td>0.581413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>gbm_lr0.1_it100_max63_min10_r0.00</td>\n",
       "      <td>0.727220</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.580885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>gbm_lr0.1_it100_max63_min10_r0.02</td>\n",
       "      <td>0.727797</td>\n",
       "      <td>0.257862</td>\n",
       "      <td>0.577955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>gbm_lr0.2_it100_max31_min10_r0.02</td>\n",
       "      <td>0.724337</td>\n",
       "      <td>0.253125</td>\n",
       "      <td>0.577942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>gbm_lr0.2_it200_max63_min20_r0.02</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.252199</td>\n",
       "      <td>0.576468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>gbm_lr0.2_it200_max63_min20_r0.00</td>\n",
       "      <td>0.708189</td>\n",
       "      <td>0.260234</td>\n",
       "      <td>0.574896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>gbm_lr0.2_it100_max63_min10_r0.02</td>\n",
       "      <td>0.719146</td>\n",
       "      <td>0.242613</td>\n",
       "      <td>0.574121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>gbm_lr0.2_it200_max31_min20_r0.00</td>\n",
       "      <td>0.712226</td>\n",
       "      <td>0.258544</td>\n",
       "      <td>0.573630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>gbm_lr0.2_it200_max31_min20_r0.02</td>\n",
       "      <td>0.708189</td>\n",
       "      <td>0.247024</td>\n",
       "      <td>0.572144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>gbm_lr0.1_it200_max63_min10_r0.00</td>\n",
       "      <td>0.708766</td>\n",
       "      <td>0.245142</td>\n",
       "      <td>0.571007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>gbm_lr0.2_it200_max31_min10_r0.00</td>\n",
       "      <td>0.707036</td>\n",
       "      <td>0.263768</td>\n",
       "      <td>0.567125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>gbm_lr0.1_it200_max63_min10_r0.02</td>\n",
       "      <td>0.715686</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.565024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>gbm_lr0.2_it200_max31_min10_r0.02</td>\n",
       "      <td>0.714533</td>\n",
       "      <td>0.264487</td>\n",
       "      <td>0.565014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>gbm_lr0.2_it100_max63_min10_r0.00</td>\n",
       "      <td>0.714533</td>\n",
       "      <td>0.251135</td>\n",
       "      <td>0.564290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>gbm_lr0.2_it200_max63_min10_r0.02</td>\n",
       "      <td>0.706459</td>\n",
       "      <td>0.232278</td>\n",
       "      <td>0.559808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>gbm_lr0.2_it200_max63_min10_r0.00</td>\n",
       "      <td>0.699539</td>\n",
       "      <td>0.246020</td>\n",
       "      <td>0.551905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       experiment_name       acc    f1_pos   roc_auc\n",
       "27   gbm_lr0.1_it100_max31_min20_r0.02  0.751442  0.273187  0.606639\n",
       "20   gbm_lr0.1_it100_max31_min20_r0.00  0.737601  0.242928  0.605682\n",
       "48   gbm_lr0.1_it100_max63_min20_r0.00  0.742215  0.258706  0.603535\n",
       "13   gbm_lr0.1_it100_max31_min10_r0.02  0.751442  0.282862  0.601420\n",
       "6    gbm_lr0.1_it100_max31_min10_r0.00  0.747982  0.255537  0.598858\n",
       "76   gbm_lr0.1_it200_max31_min20_r0.00  0.728950  0.246795  0.594175\n",
       "104  gbm_lr0.1_it200_max63_min20_r0.00  0.725490  0.253918  0.592889\n",
       "55   gbm_lr0.1_it100_max63_min20_r0.02  0.737024  0.242525  0.592759\n",
       "83   gbm_lr0.1_it200_max31_min20_r0.02  0.732987  0.263911  0.590530\n",
       "69   gbm_lr0.1_it200_max31_min10_r0.02  0.738178  0.295031  0.589123\n",
       "167  gbm_lr0.2_it100_max63_min20_r0.02  0.725490  0.251572  0.585793\n",
       "160  gbm_lr0.2_it100_max63_min20_r0.00  0.714533  0.248862  0.584456\n",
       "111  gbm_lr0.1_it200_max63_min20_r0.02  0.722030  0.260736  0.584347\n",
       "132  gbm_lr0.2_it100_max31_min20_r0.00  0.724337  0.246057  0.583764\n",
       "118  gbm_lr0.2_it100_max31_min10_r0.00  0.727220  0.275651  0.582768\n",
       "139  gbm_lr0.2_it100_max31_min20_r0.02  0.726644  0.254717  0.582320\n",
       "62   gbm_lr0.1_it200_max31_min10_r0.00  0.716263  0.261261  0.581413\n",
       "34   gbm_lr0.1_it100_max63_min10_r0.00  0.727220  0.245614  0.580885\n",
       "41   gbm_lr0.1_it100_max63_min10_r0.02  0.727797  0.257862  0.577955\n",
       "125  gbm_lr0.2_it100_max31_min10_r0.02  0.724337  0.253125  0.577942\n",
       "223  gbm_lr0.2_it200_max63_min20_r0.02  0.705882  0.252199  0.576468\n",
       "216  gbm_lr0.2_it200_max63_min20_r0.00  0.708189  0.260234  0.574896\n",
       "153  gbm_lr0.2_it100_max63_min10_r0.02  0.719146  0.242613  0.574121\n",
       "188  gbm_lr0.2_it200_max31_min20_r0.00  0.712226  0.258544  0.573630\n",
       "195  gbm_lr0.2_it200_max31_min20_r0.02  0.708189  0.247024  0.572144\n",
       "90   gbm_lr0.1_it200_max63_min10_r0.00  0.708766  0.245142  0.571007\n",
       "174  gbm_lr0.2_it200_max31_min10_r0.00  0.707036  0.263768  0.567125\n",
       "97   gbm_lr0.1_it200_max63_min10_r0.02  0.715686  0.256410  0.565024\n",
       "181  gbm_lr0.2_it200_max31_min10_r0.02  0.714533  0.264487  0.565014\n",
       "146  gbm_lr0.2_it100_max63_min10_r0.00  0.714533  0.251135  0.564290\n",
       "209  gbm_lr0.2_it200_max63_min10_r0.02  0.706459  0.232278  0.559808\n",
       "202  gbm_lr0.2_it200_max63_min10_r0.00  0.699539  0.246020  0.551905"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameter tuning when biomarker features are excluded\n",
    "# no longer captured in cell order\n",
    "metrics = pd.DataFrame(metrics_list)\n",
    "metrics.loc[metrics.institution_name == \"All\", [\"experiment_name\", \"acc\", \"f1_pos\", \"roc_auc\"]].sort_values(\n",
    "    by=\"roc_auc\", ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "209ef45f-cd1f-4473-a9fe-b9f297d58b31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1_pos</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>gbm_lr0.2_it200_max31_min10</td>\n",
       "      <td>0.906574</td>\n",
       "      <td>0.758209</td>\n",
       "      <td>0.943299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>gbm_lr0.2_it100_max31_min10</td>\n",
       "      <td>0.907728</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.942696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>gbm_lr0.1_it200_max31_min10</td>\n",
       "      <td>0.907728</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.941163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>gbm_lr0.2_it200_max63_min10</td>\n",
       "      <td>0.906574</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.940678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gbm_lr0.1_it100_max31_min10</td>\n",
       "      <td>0.908881</td>\n",
       "      <td>0.764881</td>\n",
       "      <td>0.940313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>gbm_lr0.1_it200_max63_min10</td>\n",
       "      <td>0.905998</td>\n",
       "      <td>0.757079</td>\n",
       "      <td>0.939671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>gbm_lr0.2_it100_max63_min10</td>\n",
       "      <td>0.908304</td>\n",
       "      <td>0.761619</td>\n",
       "      <td>0.939545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>gbm_lr0.1_it200_max31_min20</td>\n",
       "      <td>0.904844</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.938255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gbm_lr0.1_it100_max63_min10</td>\n",
       "      <td>0.908881</td>\n",
       "      <td>0.767647</td>\n",
       "      <td>0.937464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>gbm_lr0.2_it200_max63_min20</td>\n",
       "      <td>0.904268</td>\n",
       "      <td>0.747720</td>\n",
       "      <td>0.937444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>gbm_lr0.2_it100_max63_min20</td>\n",
       "      <td>0.904268</td>\n",
       "      <td>0.749245</td>\n",
       "      <td>0.937126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gbm_lr0.1_it100_max31_min20</td>\n",
       "      <td>0.901384</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.936955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>gbm_lr0.1_it100_max63_min20</td>\n",
       "      <td>0.906574</td>\n",
       "      <td>0.758929</td>\n",
       "      <td>0.936502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>gbm_lr0.1_it200_max63_min20</td>\n",
       "      <td>0.905421</td>\n",
       "      <td>0.752266</td>\n",
       "      <td>0.935840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>gbm_lr0.2_it200_max31_min20</td>\n",
       "      <td>0.901384</td>\n",
       "      <td>0.737327</td>\n",
       "      <td>0.935646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>gbm_lr0.2_it100_max31_min20</td>\n",
       "      <td>0.900807</td>\n",
       "      <td>0.736196</td>\n",
       "      <td>0.935027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 experiment_name       acc    f1_pos   roc_auc\n",
       "90   gbm_lr0.2_it200_max31_min10  0.906574  0.758209  0.943299\n",
       "62   gbm_lr0.2_it100_max31_min10  0.907728  0.761905  0.942696\n",
       "34   gbm_lr0.1_it200_max31_min10  0.907728  0.759036  0.941163\n",
       "104  gbm_lr0.2_it200_max63_min10  0.906574  0.756757  0.940678\n",
       "6    gbm_lr0.1_it100_max31_min10  0.908881  0.764881  0.940313\n",
       "48   gbm_lr0.1_it200_max63_min10  0.905998  0.757079  0.939671\n",
       "76   gbm_lr0.2_it100_max63_min10  0.908304  0.761619  0.939545\n",
       "41   gbm_lr0.1_it200_max31_min20  0.904844  0.751131  0.938255\n",
       "20   gbm_lr0.1_it100_max63_min10  0.908881  0.767647  0.937464\n",
       "111  gbm_lr0.2_it200_max63_min20  0.904268  0.747720  0.937444\n",
       "83   gbm_lr0.2_it100_max63_min20  0.904268  0.749245  0.937126\n",
       "13   gbm_lr0.1_it100_max31_min20  0.901384  0.742857  0.936955\n",
       "27   gbm_lr0.1_it100_max63_min20  0.906574  0.758929  0.936502\n",
       "55   gbm_lr0.1_it200_max63_min20  0.905421  0.752266  0.935840\n",
       "97   gbm_lr0.2_it200_max31_min20  0.901384  0.737327  0.935646\n",
       "69   gbm_lr0.2_it100_max31_min20  0.900807  0.736196  0.935027"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameter tuning when biomarker features are included raw\n",
    "# no longer captured in cell order\n",
    "metrics = pd.DataFrame(metrics_list)\n",
    "metrics.loc[metrics.institution_name == \"All\", [\"experiment_name\", \"acc\", \"f1_pos\", \"roc_auc\"]].sort_values(\n",
    "    by=\"roc_auc\", ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c938f767-0bd3-4755-86c9-5f1d8d900cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs = []\n",
    "for biomarker_svd_n_components in [None, 10, 50, 100, 1000]:\n",
    "    config = bcs.modeling.ModelingConfig(\n",
    "        experiment_name=f\"gbm_svd{biomarker_svd_n_components}\",\n",
    "        gbm_learning_rate=0.2,\n",
    "        gbm_max_iter=200,\n",
    "        gbm_max_leaf_nodes=31,\n",
    "        gbm_min_samples_leaf=10,\n",
    "        gbm_l2_regularization=0.01,\n",
    "        biomarker_feature_action=\"svd\",\n",
    "        biomarker_svd_n_components=biomarker_svd_n_components,\n",
    "    )\n",
    "    configs.append(config)\n",
    "assert len(configs) == len({c.experiment_name for c in configs}), \"Experiment names not unique.\"\n",
    "len(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7304d06c-294f-4de7-bc5b-f7d3ebef095a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD experiments:  83%|██████████████████████████████████████████████████████████████████████████████▎               | 5/6 [12:22<02:28, 148.47s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_components=10000 must be between 0 and min(n_samples, n_features)=1038 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m config \u001b[38;5;129;01min\u001b[39;00m tqdm(configs, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD experiments\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      3\u001b[0m     model_evaluator \u001b[38;5;241m=\u001b[39m bcs\u001b[38;5;241m.\u001b[39mmodeling\u001b[38;5;241m.\u001b[39mModelEvaluator(config, mdf)\n\u001b[0;32m----> 4\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_evaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     model_list\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mlen\u001b[39m(model)\n",
      "File \u001b[0;32m~/repos/biomarker-case-study/src/bcs/modeling.py:83\u001b[0m, in \u001b[0;36mModelEvaluator.train_and_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_and_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     82\u001b[0m     model \u001b[38;5;241m=\u001b[39m GbmModel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[0;32m---> 83\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/repos/biomarker-case-study/src/bcs/modeling.py:117\u001b[0m, in \u001b[0;36mGbmModel.fit_eval\u001b[0;34m(self, df, all_feature_columns, categorical_columns)\u001b[0m\n\u001b[1;32m    115\u001b[0m y_true_all \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mtarget_label\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    116\u001b[0m y_pred_all \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mtarget_label\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m y_score_all \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mtarget_label\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    119\u001b[0m biomarker_columns \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m all_feature_columns \u001b[38;5;28;01mif\u001b[39;00m col\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBM\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m    120\u001b[0m nonbiomarker_columns \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m all_feature_columns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m biomarker_columns]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bcs-2o8BH1Ry-py3.11/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bcs-2o8BH1Ry-py3.11/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:462\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;124;03mC-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 462\u001b[0m U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhiten:\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;66;03m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bcs-2o8BH1Ry-py3.11/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:512\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomized\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_truncated(X, n_components, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bcs-2o8BH1Ry-py3.11/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:526\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    523\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is only supported if n_samples >= n_features\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    524\u001b[0m         )\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n_components \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_samples, n_features):\n\u001b[0;32m--> 526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m must be between 0 and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin(n_samples, n_features)=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    529\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd_solver=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_components, \u001b[38;5;28mmin\u001b[39m(n_samples, n_features))\n\u001b[1;32m    530\u001b[0m     )\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Center data\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: n_components=10000 must be between 0 and min(n_samples, n_features)=1038 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "for config in tqdm(configs, desc=\"SVD experiments\"):\n",
    "    model_evaluator = bcs.modeling.ModelEvaluator(config, mdf)\n",
    "    model = model_evaluator.train_and_evaluate()\n",
    "    model_list.append(model)\n",
    "len(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9accbb6-0301-4be4-b8c5-f9249cb90178",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1_pos</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>gbm_svd100</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.613485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gbm_svd50</td>\n",
       "      <td>0.777970</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.610542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gbm_svd10</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.597756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>gbm_svd1000</td>\n",
       "      <td>0.779700</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>0.593636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gbm_svdNone</td>\n",
       "      <td>0.777970</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.592006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiment_name       acc    f1_pos   roc_auc\n",
       "27      gbm_svd100  0.764706  0.209302  0.613485\n",
       "20       gbm_svd50  0.777970  0.067797  0.610542\n",
       "13       gbm_svd10  0.764706  0.227273  0.597756\n",
       "34     gbm_svd1000  0.779700  0.010363  0.593636\n",
       "6      gbm_svdNone  0.777970  0.005168  0.592006"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameter tuning with SVD\n",
    "# no longer captured in cell order\n",
    "metrics_list = []\n",
    "for model in model_list:\n",
    "    metrics_list.extend(model.metrics_)\n",
    "metrics = pd.DataFrame(metrics_list)\n",
    "metrics.loc[metrics.institution_name == \"All\", [\"experiment_name\", \"acc\", \"f1_pos\", \"roc_auc\"]].sort_values(\n",
    "    by=\"roc_auc\", ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbeb214-d526-4ca4-8c3e-ec2ec7575990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d411662f-3416-49b1-ae18-936a5e4ec5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcs",
   "language": "python",
   "name": "bcs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
